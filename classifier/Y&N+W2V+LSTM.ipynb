{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Y&N+W2V+LSTM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOg5tx8zN1MbVyjJk1CNnSZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Qxwjra1zMwRn","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EoAFmQESgt2T","colab_type":"code","colab":{}},"source":["!pip install konlpy\n","!pip install kss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MVhuHgC-hVRH","colab_type":"code","colab":{}},"source":["!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-3StvQXhdUP","colab_type":"code","colab":{}},"source":["cd Mecab-ko-for-Google-Colab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnT2v3CYhf3_","colab_type":"code","colab":{}},"source":["!bash install_mecab-ko_on_colab190912.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbHA9THA_SIl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a751e72d-4e6d-4910-c349-37953c712e73"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import copy\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Activation\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder; LE = LabelEncoder()\n","from sklearn.metrics import classification_report\n","from gensim.models.word2vec import Word2Vec\n","from konlpy.tag import Mecab\n","\n","def lstm():\n","    model = Sequential()\n","    model.add(LSTM(2 ** 3, input_shape=(max_len*100, 1), return_sequences=True))\n","    model.add(LSTM(2 ** 3, return_sequences=True))\n","    model.add(LSTM(2 ** 3, return_sequences=False))\n","\n","    model.add(Dense(2))\n","    model.add(Activation('softmax'))\n","    adam = optimizers.Adam(lr=0.001)\n","    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n","    model.summary()\n","    early_stopping = EarlyStopping(patience=10)\n","    history = model.fit(x_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n","\n","    return model, history\n","\n","if __name__ == \"__main__\":\n","    max_len = 32\n","    epochs = 2 ** 10\n","    batch_size = 2 ** 10\n","\n","    mecab = Mecab()\n","\n","    model = Word2Vec.load('/gdrive/My Drive/한양대학교/2020 프로젝트 학기제/TEST/word2vec')\n","\n","    depression_dataset_path = r'/gdrive/My Drive/한양대학교/2020 프로젝트 학기제/TEST/depression_dataset_맞춤법O.csv'\n","\n","    depression_dataset = pd.read_csv(depression_dataset_path, encoding='cp949')\n","\n","    df = []\n","\n","    for i in range(len(depression_dataset)):\n","        df.append(mecab.morphs(depression_dataset.iloc[i,0]))\n","\n","    for i in range(len(df)):\n","        for j in range(len(df[i])):\n","            try:\n","                df[i][j] = model.wv.get_vector(df[i][j]).tolist()\n","            except:\n","                df[i][j] = False\n","\n","    for i in range(len(df)):\n","        while False in df[i]:\n","            df[i].remove(False)\n","\n","    for i in range(len(df)):\n","        if len(df[i]) >= max_len:\n","            df[i] = df[i][-32:]\n","        else:\n","            for j in range(max_len-len(df[i])):\n","                df[i].insert(0,0)\n","\n","    for i in range(len(df)):\n","        for j in range(len(df[i])):\n","            if df[i][j] == 0:\n","                df[i][j] = [0]*100\n","\n","    depression_dataset['label_1'] = LE.fit_transform(depression_dataset['label_1'])\n","\n","    x_train, x_test, y_train, y_test = train_test_split(df, depression_dataset['label_1'], test_size=0.1, random_state=42)\n","\n","    x_train = np.array(x_train).reshape((len(x_train), max_len*100, 1))\n","    x_test = np.array(x_test).reshape((len(x_test), max_len*100, 1))\n","\n","    y_true = copy.deepcopy(y_test)\n","    y_train = to_categorical(y_train)\n","    y_test = to_categorical(y_test)\n","\n","    print('train_shape : {} / {}'.format(x_train.shape, y_train.shape))\n","    print('test_shape : {} / {}'.format(x_test.shape, y_test.shape))\n","\n","    model, history = lstm()\n","\n","    scores = model.evaluate(x_test, y_test)\n","    print(scores)\n","    print(\"정확도: %.2f%%\" % (scores[1] * 100))\n","\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(1, len(acc) + 1)\n","\n","    plt.plot(epochs, loss, 'r', label='Training loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.figure()\n","    plt.plot(epochs, acc, 'r', label='Training acc')\n","    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","    plt.title('Training and validation accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n","\n","    y_true = list(y_true)\n","    y_pred = model.predict_classes(x_test)\n","    y_pred = list(y_pred)\n","\n","    print(classification_report(y_true, y_pred))\n","    print(pd.crosstab(pd.Series(y_true), pd.Series(y_pred), rownames=['True'], colnames=['Predicted']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["train_shape : (25873, 3200, 1) / (25873, 2)\n","test_shape : (2875, 3200, 1) / (2875, 2)\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 3200, 8)           320       \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 3200, 8)           544       \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 8)                 544       \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 18        \n","_________________________________________________________________\n","activation (Activation)      (None, 2)                 0         \n","=================================================================\n","Total params: 1,426\n","Trainable params: 1,426\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6938 - accuracy: 0.4872 - val_loss: 0.6935 - val_accuracy: 0.4938\n","Epoch 2/1024\n","23/23 [==============================] - 210s 9s/step - loss: 0.6929 - accuracy: 0.5081 - val_loss: 0.6924 - val_accuracy: 0.5943\n","Epoch 3/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6917 - accuracy: 0.5701 - val_loss: 0.6905 - val_accuracy: 0.4517\n","Epoch 4/1024\n","23/23 [==============================] - 210s 9s/step - loss: 0.6884 - accuracy: 0.5494 - val_loss: 0.6840 - val_accuracy: 0.5773\n","Epoch 5/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6802 - accuracy: 0.5761 - val_loss: 0.6654 - val_accuracy: 0.5858\n","Epoch 6/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6676 - accuracy: 0.5689 - val_loss: 0.6562 - val_accuracy: 0.5804\n","Epoch 7/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6598 - accuracy: 0.5732 - val_loss: 0.6494 - val_accuracy: 0.5707\n","Epoch 8/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6538 - accuracy: 0.5792 - val_loss: 0.6426 - val_accuracy: 0.5823\n","Epoch 9/1024\n","23/23 [==============================] - 209s 9s/step - loss: 0.6500 - accuracy: 0.6178 - val_loss: 0.6392 - val_accuracy: 0.6329\n","Epoch 10/1024\n","23/23 [==============================] - 208s 9s/step - loss: 0.6476 - accuracy: 0.6219 - val_loss: 0.6382 - val_accuracy: 0.6306\n","Epoch 11/1024\n","23/23 [==============================] - 210s 9s/step - loss: 0.6463 - accuracy: 0.6235 - val_loss: 0.6391 - val_accuracy: 0.6256\n","Epoch 12/1024\n","23/23 [==============================] - 209s 9s/step - loss: 0.6441 - accuracy: 0.6182 - val_loss: 0.6336 - val_accuracy: 0.6248\n","Epoch 13/1024\n","23/23 [==============================] - 208s 9s/step - loss: 0.6435 - accuracy: 0.6195 - val_loss: 0.6332 - val_accuracy: 0.6217\n","Epoch 14/1024\n","23/23 [==============================] - 210s 9s/step - loss: 0.6423 - accuracy: 0.6168 - val_loss: 0.6321 - val_accuracy: 0.6256\n","Epoch 15/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6410 - accuracy: 0.6181 - val_loss: 0.6316 - val_accuracy: 0.6198\n","Epoch 16/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6407 - accuracy: 0.6155 - val_loss: 0.6308 - val_accuracy: 0.6233\n","Epoch 17/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6405 - accuracy: 0.6143 - val_loss: 0.6303 - val_accuracy: 0.6213\n","Epoch 18/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6406 - accuracy: 0.6117 - val_loss: 0.6313 - val_accuracy: 0.6209\n","Epoch 19/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6406 - accuracy: 0.6128 - val_loss: 0.6306 - val_accuracy: 0.6217\n","Epoch 20/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6388 - accuracy: 0.6152 - val_loss: 0.6286 - val_accuracy: 0.6090\n","Epoch 21/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6384 - accuracy: 0.6112 - val_loss: 0.6287 - val_accuracy: 0.6105\n","Epoch 22/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6380 - accuracy: 0.6125 - val_loss: 0.6291 - val_accuracy: 0.6233\n","Epoch 23/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6374 - accuracy: 0.6126 - val_loss: 0.6277 - val_accuracy: 0.6244\n","Epoch 24/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6372 - accuracy: 0.6133 - val_loss: 0.6277 - val_accuracy: 0.6260\n","Epoch 25/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6367 - accuracy: 0.6116 - val_loss: 0.6262 - val_accuracy: 0.6271\n","Epoch 26/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6354 - accuracy: 0.6174 - val_loss: 0.6253 - val_accuracy: 0.6279\n","Epoch 27/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6345 - accuracy: 0.6147 - val_loss: 0.6241 - val_accuracy: 0.6302\n","Epoch 28/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6337 - accuracy: 0.6175 - val_loss: 0.6236 - val_accuracy: 0.6264\n","Epoch 29/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6336 - accuracy: 0.6195 - val_loss: 0.6259 - val_accuracy: 0.6267\n","Epoch 30/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6334 - accuracy: 0.6187 - val_loss: 0.6202 - val_accuracy: 0.6310\n","Epoch 31/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6311 - accuracy: 0.6222 - val_loss: 0.6198 - val_accuracy: 0.6190\n","Epoch 32/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6298 - accuracy: 0.6214 - val_loss: 0.6170 - val_accuracy: 0.6190\n","Epoch 33/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6287 - accuracy: 0.6202 - val_loss: 0.6184 - val_accuracy: 0.6418\n","Epoch 34/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6272 - accuracy: 0.6274 - val_loss: 0.6172 - val_accuracy: 0.6445\n","Epoch 35/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6267 - accuracy: 0.6369 - val_loss: 0.6137 - val_accuracy: 0.6468\n","Epoch 36/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6249 - accuracy: 0.6432 - val_loss: 0.6122 - val_accuracy: 0.6472\n","Epoch 37/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6247 - accuracy: 0.6396 - val_loss: 0.6141 - val_accuracy: 0.6596\n","Epoch 38/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6245 - accuracy: 0.6402 - val_loss: 0.6092 - val_accuracy: 0.6580\n","Epoch 39/1024\n","23/23 [==============================] - 220s 10s/step - loss: 0.6241 - accuracy: 0.6433 - val_loss: 0.6095 - val_accuracy: 0.6662\n","Epoch 40/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6238 - accuracy: 0.6451 - val_loss: 0.6111 - val_accuracy: 0.6604\n","Epoch 41/1024\n","23/23 [==============================] - 221s 10s/step - loss: 0.6213 - accuracy: 0.6498 - val_loss: 0.6074 - val_accuracy: 0.6665\n","Epoch 42/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6202 - accuracy: 0.6508 - val_loss: 0.6072 - val_accuracy: 0.6642\n","Epoch 43/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6195 - accuracy: 0.6525 - val_loss: 0.6075 - val_accuracy: 0.6611\n","Epoch 44/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6204 - accuracy: 0.6502 - val_loss: 0.6050 - val_accuracy: 0.6727\n","Epoch 45/1024\n","23/23 [==============================] - 219s 10s/step - loss: 0.6233 - accuracy: 0.6496 - val_loss: 0.6043 - val_accuracy: 0.6719\n","Epoch 46/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6213 - accuracy: 0.6516 - val_loss: 0.6162 - val_accuracy: 0.6631\n","Epoch 47/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6204 - accuracy: 0.6514 - val_loss: 0.6069 - val_accuracy: 0.6689\n","Epoch 48/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6182 - accuracy: 0.6550 - val_loss: 0.6071 - val_accuracy: 0.6692\n","Epoch 49/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6176 - accuracy: 0.6549 - val_loss: 0.6031 - val_accuracy: 0.6696\n","Epoch 50/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6171 - accuracy: 0.6551 - val_loss: 0.6069 - val_accuracy: 0.6712\n","Epoch 51/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6177 - accuracy: 0.6560 - val_loss: 0.6041 - val_accuracy: 0.6739\n","Epoch 52/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6164 - accuracy: 0.6554 - val_loss: 0.6048 - val_accuracy: 0.6735\n","Epoch 53/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6161 - accuracy: 0.6569 - val_loss: 0.6039 - val_accuracy: 0.6650\n","Epoch 54/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6187 - accuracy: 0.6556 - val_loss: 0.6020 - val_accuracy: 0.6692\n","Epoch 55/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6184 - accuracy: 0.6543 - val_loss: 0.6046 - val_accuracy: 0.6642\n","Epoch 56/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6192 - accuracy: 0.6523 - val_loss: 0.6022 - val_accuracy: 0.6662\n","Epoch 57/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6157 - accuracy: 0.6560 - val_loss: 0.6025 - val_accuracy: 0.6654\n","Epoch 58/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6155 - accuracy: 0.6555 - val_loss: 0.6042 - val_accuracy: 0.6708\n","Epoch 59/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6149 - accuracy: 0.6558 - val_loss: 0.6027 - val_accuracy: 0.6689\n","Epoch 60/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6156 - accuracy: 0.6553 - val_loss: 0.6008 - val_accuracy: 0.6638\n","Epoch 61/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6160 - accuracy: 0.6564 - val_loss: 0.6043 - val_accuracy: 0.6692\n","Epoch 62/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6145 - accuracy: 0.6554 - val_loss: 0.6020 - val_accuracy: 0.6692\n","Epoch 63/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6142 - accuracy: 0.6571 - val_loss: 0.6022 - val_accuracy: 0.6743\n","Epoch 64/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6152 - accuracy: 0.6551 - val_loss: 0.6052 - val_accuracy: 0.6727\n","Epoch 65/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6159 - accuracy: 0.6539 - val_loss: 0.6062 - val_accuracy: 0.6569\n","Epoch 66/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6154 - accuracy: 0.6562 - val_loss: 0.6028 - val_accuracy: 0.6673\n","Epoch 67/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6143 - accuracy: 0.6558 - val_loss: 0.6021 - val_accuracy: 0.6716\n","Epoch 68/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6142 - accuracy: 0.6566 - val_loss: 0.6030 - val_accuracy: 0.6700\n","Epoch 69/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6139 - accuracy: 0.6573 - val_loss: 0.6011 - val_accuracy: 0.6712\n","Epoch 70/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6133 - accuracy: 0.6581 - val_loss: 0.6005 - val_accuracy: 0.6719\n","Epoch 71/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6143 - accuracy: 0.6574 - val_loss: 0.6019 - val_accuracy: 0.6700\n","Epoch 72/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6141 - accuracy: 0.6572 - val_loss: 0.6019 - val_accuracy: 0.6704\n","Epoch 73/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6132 - accuracy: 0.6565 - val_loss: 0.6001 - val_accuracy: 0.6700\n","Epoch 74/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6125 - accuracy: 0.6578 - val_loss: 0.6022 - val_accuracy: 0.6727\n","Epoch 75/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6130 - accuracy: 0.6575 - val_loss: 0.6024 - val_accuracy: 0.6743\n","Epoch 76/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6148 - accuracy: 0.6557 - val_loss: 0.6010 - val_accuracy: 0.6739\n","Epoch 77/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6126 - accuracy: 0.6578 - val_loss: 0.5998 - val_accuracy: 0.6727\n","Epoch 78/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6120 - accuracy: 0.6586 - val_loss: 0.6021 - val_accuracy: 0.6719\n","Epoch 79/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6127 - accuracy: 0.6589 - val_loss: 0.5997 - val_accuracy: 0.6727\n","Epoch 80/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6119 - accuracy: 0.6581 - val_loss: 0.5998 - val_accuracy: 0.6708\n","Epoch 81/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6116 - accuracy: 0.6583 - val_loss: 0.5991 - val_accuracy: 0.6747\n","Epoch 82/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6123 - accuracy: 0.6582 - val_loss: 0.6004 - val_accuracy: 0.6739\n","Epoch 83/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6120 - accuracy: 0.6577 - val_loss: 0.6016 - val_accuracy: 0.6727\n","Epoch 84/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6122 - accuracy: 0.6581 - val_loss: 0.6009 - val_accuracy: 0.6727\n","Epoch 85/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6120 - accuracy: 0.6580 - val_loss: 0.5995 - val_accuracy: 0.6735\n","Epoch 86/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6117 - accuracy: 0.6586 - val_loss: 0.6006 - val_accuracy: 0.6750\n","Epoch 87/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6117 - accuracy: 0.6588 - val_loss: 0.6001 - val_accuracy: 0.6743\n","Epoch 88/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6127 - accuracy: 0.6584 - val_loss: 0.5993 - val_accuracy: 0.6743\n","Epoch 89/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6118 - accuracy: 0.6591 - val_loss: 0.5986 - val_accuracy: 0.6843\n","Epoch 90/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6136 - accuracy: 0.6560 - val_loss: 0.6003 - val_accuracy: 0.6735\n","Epoch 91/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6124 - accuracy: 0.6575 - val_loss: 0.5976 - val_accuracy: 0.6774\n","Epoch 92/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6119 - accuracy: 0.6594 - val_loss: 0.5994 - val_accuracy: 0.6739\n","Epoch 93/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6115 - accuracy: 0.6597 - val_loss: 0.5977 - val_accuracy: 0.6770\n","Epoch 94/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6146 - accuracy: 0.6547 - val_loss: 0.6016 - val_accuracy: 0.6700\n","Epoch 95/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6122 - accuracy: 0.6594 - val_loss: 0.6006 - val_accuracy: 0.6743\n","Epoch 96/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6119 - accuracy: 0.6577 - val_loss: 0.6011 - val_accuracy: 0.6743\n","Epoch 97/1024\n","23/23 [==============================] - 219s 10s/step - loss: 0.6119 - accuracy: 0.6572 - val_loss: 0.5990 - val_accuracy: 0.6731\n","Epoch 98/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6114 - accuracy: 0.6606 - val_loss: 0.5989 - val_accuracy: 0.6731\n","Epoch 99/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6108 - accuracy: 0.6593 - val_loss: 0.5987 - val_accuracy: 0.6750\n","Epoch 100/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6105 - accuracy: 0.6584 - val_loss: 0.5983 - val_accuracy: 0.6750\n","Epoch 101/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6105 - accuracy: 0.6594 - val_loss: 0.5975 - val_accuracy: 0.6739\n","Epoch 102/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6105 - accuracy: 0.6583 - val_loss: 0.5976 - val_accuracy: 0.6862\n","Epoch 103/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6107 - accuracy: 0.6593 - val_loss: 0.6002 - val_accuracy: 0.6747\n","Epoch 104/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6107 - accuracy: 0.6591 - val_loss: 0.5975 - val_accuracy: 0.6750\n","Epoch 105/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6107 - accuracy: 0.6589 - val_loss: 0.5982 - val_accuracy: 0.6731\n","Epoch 106/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6122 - accuracy: 0.6571 - val_loss: 0.6001 - val_accuracy: 0.6777\n","Epoch 107/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6113 - accuracy: 0.6589 - val_loss: 0.5979 - val_accuracy: 0.6754\n","Epoch 108/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6101 - accuracy: 0.6598 - val_loss: 0.5980 - val_accuracy: 0.6770\n","Epoch 109/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6098 - accuracy: 0.6597 - val_loss: 0.5970 - val_accuracy: 0.6851\n","Epoch 110/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6106 - accuracy: 0.6591 - val_loss: 0.5975 - val_accuracy: 0.6747\n","Epoch 111/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6104 - accuracy: 0.6597 - val_loss: 0.5992 - val_accuracy: 0.6716\n","Epoch 112/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6117 - accuracy: 0.6600 - val_loss: 0.5982 - val_accuracy: 0.6747\n","Epoch 113/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6114 - accuracy: 0.6588 - val_loss: 0.5981 - val_accuracy: 0.6739\n","Epoch 114/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6102 - accuracy: 0.6597 - val_loss: 0.5964 - val_accuracy: 0.6859\n","Epoch 115/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6101 - accuracy: 0.6597 - val_loss: 0.5975 - val_accuracy: 0.6762\n","Epoch 116/1024\n","23/23 [==============================] - 216s 9s/step - loss: 0.6102 - accuracy: 0.6584 - val_loss: 0.5978 - val_accuracy: 0.6743\n","Epoch 117/1024\n","23/23 [==============================] - 217s 9s/step - loss: 0.6097 - accuracy: 0.6575 - val_loss: 0.5964 - val_accuracy: 0.6793\n","Epoch 118/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6093 - accuracy: 0.6591 - val_loss: 0.5973 - val_accuracy: 0.6743\n","Epoch 119/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6097 - accuracy: 0.6610 - val_loss: 0.6011 - val_accuracy: 0.6801\n","Epoch 120/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6098 - accuracy: 0.6581 - val_loss: 0.5980 - val_accuracy: 0.6754\n","Epoch 121/1024\n","23/23 [==============================] - 214s 9s/step - loss: 0.6101 - accuracy: 0.6581 - val_loss: 0.5983 - val_accuracy: 0.6754\n","Epoch 122/1024\n","23/23 [==============================] - 211s 9s/step - loss: 0.6093 - accuracy: 0.6592 - val_loss: 0.5990 - val_accuracy: 0.6754\n","Epoch 123/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6097 - accuracy: 0.6589 - val_loss: 0.5972 - val_accuracy: 0.6766\n","Epoch 124/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6101 - accuracy: 0.6606 - val_loss: 0.5962 - val_accuracy: 0.6870\n","Epoch 125/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6098 - accuracy: 0.6618 - val_loss: 0.5962 - val_accuracy: 0.6843\n","Epoch 126/1024\n","23/23 [==============================] - 212s 9s/step - loss: 0.6090 - accuracy: 0.6599 - val_loss: 0.5961 - val_accuracy: 0.6747\n","Epoch 127/1024\n","23/23 [==============================] - 213s 9s/step - loss: 0.6089 - accuracy: 0.6599 - val_loss: 0.5963 - val_accuracy: 0.6727\n","Epoch 128/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6093 - accuracy: 0.6600 - val_loss: 0.5978 - val_accuracy: 0.6824\n","Epoch 129/1024\n","23/23 [==============================] - 215s 9s/step - loss: 0.6094 - accuracy: 0.6619 - val_loss: 0.5952 - val_accuracy: 0.6843\n","Epoch 130/1024\n","23/23 [==============================] - 219s 10s/step - loss: 0.6088 - accuracy: 0.6591 - val_loss: 0.5960 - val_accuracy: 0.6770\n","Epoch 131/1024\n","23/23 [==============================] - 218s 9s/step - loss: 0.6088 - accuracy: 0.6600 - val_loss: 0.5947 - val_accuracy: 0.6870\n","Epoch 132/1024\n","21/23 [==========================>...] - ETA: 18s - loss: 0.6082 - accuracy: 0.6590"],"name":"stdout"}]}]}