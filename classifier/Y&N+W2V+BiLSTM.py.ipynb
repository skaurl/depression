{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Y&N+W2V+BiLSTM.py.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOnFcpfxfR8RH5zrnaxKUHX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Qxwjra1zMwRn","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EoAFmQESgt2T","colab_type":"code","colab":{}},"source":["!pip install konlpy\n","!pip install kss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MVhuHgC-hVRH","colab_type":"code","colab":{}},"source":["!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-3StvQXhdUP","colab_type":"code","colab":{}},"source":["cd Mecab-ko-for-Google-Colab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnT2v3CYhf3_","colab_type":"code","colab":{}},"source":["!bash install_mecab-ko_on_colab190912.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbHA9THA_SIl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f3aed1fc-6212-4cf1-fa81-ba6dd5183e35"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import copy\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Activation, Bidirectional\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder; LE = LabelEncoder()\n","from sklearn.metrics import classification_report\n","from gensim.models.word2vec import Word2Vec\n","from konlpy.tag import Mecab\n","\n","def bilstm():\n","    model = Sequential()\n","    model.add(Bidirectional(LSTM(2 ** 3, return_sequences=True), input_shape=(max_len*100, 1)))\n","    model.add(Bidirectional(LSTM(2 ** 3, return_sequences=True)))\n","    model.add(Bidirectional(LSTM(2 ** 3, return_sequences=False)))\n","\n","    model.add(Dense(2))\n","    model.add(Activation('softmax'))\n","    adam = optimizers.Adam(lr=0.001)\n","    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n","    model.summary()\n","    early_stopping = EarlyStopping(patience=10)\n","    history = model.fit(x_train, y_train, validation_split=0.1, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stopping])\n","\n","    return model, history\n","\n","if __name__ == \"__main__\":\n","    max_len = 32\n","    epochs = 2 ** 10\n","    batch_size = 2 ** 10\n","\n","    mecab = Mecab()\n","\n","    model = Word2Vec.load('/gdrive/My Drive/한양대학교/2020 프로젝트 학기제/TEST/word2vec')\n","\n","    depression_dataset_path = r'/gdrive/My Drive/한양대학교/2020 프로젝트 학기제/TEST/depression_dataset_맞춤법O.csv'\n","\n","    depression_dataset = pd.read_csv(depression_dataset_path, encoding='cp949')\n","\n","    df = []\n","\n","    for i in range(len(depression_dataset)):\n","        df.append(mecab.morphs(depression_dataset.iloc[i,0]))\n","\n","    for i in range(len(df)):\n","        for j in range(len(df[i])):\n","            try:\n","                df[i][j] = model.wv.get_vector(df[i][j]).tolist()\n","            except:\n","                df[i][j] = False\n","\n","    for i in range(len(df)):\n","        while False in df[i]:\n","            df[i].remove(False)\n","\n","    for i in range(len(df)):\n","        if len(df[i]) >= max_len:\n","            df[i] = df[i][-32:]\n","        else:\n","            for j in range(max_len-len(df[i])):\n","                df[i].insert(0,0)\n","\n","    for i in range(len(df)):\n","        for j in range(len(df[i])):\n","            if df[i][j] == 0:\n","                df[i][j] = [0]*100\n","\n","    depression_dataset['label_1'] = LE.fit_transform(depression_dataset['label_1'])\n","\n","    x_train, x_test, y_train, y_test = train_test_split(df, depression_dataset['label_1'], test_size=0.1, random_state=42)\n","\n","    x_train = np.array(x_train).reshape((len(x_train), max_len*100, 1))\n","    x_test = np.array(x_test).reshape((len(x_test), max_len*100, 1))\n","\n","    y_true = copy.deepcopy(y_test)\n","    y_train = to_categorical(y_train)\n","    y_test = to_categorical(y_test)\n","\n","    print('train_shape : {} / {}'.format(x_train.shape, y_train.shape))\n","    print('test_shape : {} / {}'.format(x_test.shape, y_test.shape))\n","\n","    model, history = bilstm()\n","\n","    scores = model.evaluate(x_test, y_test)\n","    print(scores)\n","    print(\"정확도: %.2f%%\" % (scores[1] * 100))\n","\n","    acc = history.history['accuracy']\n","    val_acc = history.history['val_accuracy']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(1, len(acc) + 1)\n","\n","    plt.plot(epochs, loss, 'r', label='Training loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.figure()\n","    plt.plot(epochs, acc, 'r', label='Training acc')\n","    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","    plt.title('Training and validation accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n","\n","    y_true = list(y_true)\n","    y_pred = model.predict_classes(x_test)\n","    y_pred = list(y_pred)\n","\n","    print(classification_report(y_true, y_pred))\n","    print(pd.crosstab(pd.Series(y_true), pd.Series(y_pred), rownames=['True'], colnames=['Predicted']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["train_shape : (25873, 3200, 1) / (25873, 2)\n","test_shape : (2875, 3200, 1) / (2875, 2)\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional (Bidirectional (None, 3200, 16)          640       \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 3200, 16)          1600      \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 16)                1600      \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 34        \n","_________________________________________________________________\n","activation (Activation)      (None, 2)                 0         \n","=================================================================\n","Total params: 3,874\n","Trainable params: 3,874\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/1024\n","23/23 [==============================] - 521s 23s/step - loss: 0.6913 - accuracy: 0.5352 - val_loss: 0.6890 - val_accuracy: 0.5742\n","Epoch 2/1024\n","23/23 [==============================] - 506s 22s/step - loss: 0.6867 - accuracy: 0.5748 - val_loss: 0.6811 - val_accuracy: 0.5896\n","Epoch 3/1024\n","23/23 [==============================] - 503s 22s/step - loss: 0.6819 - accuracy: 0.5736 - val_loss: 0.6757 - val_accuracy: 0.5904\n","Epoch 4/1024\n","23/23 [==============================] - 501s 22s/step - loss: 0.6772 - accuracy: 0.5783 - val_loss: 0.6670 - val_accuracy: 0.6016\n","Epoch 5/1024\n","23/23 [==============================] - 502s 22s/step - loss: 0.6639 - accuracy: 0.5771 - val_loss: 0.6462 - val_accuracy: 0.5730\n","Epoch 6/1024\n","23/23 [==============================] - 502s 22s/step - loss: 0.6492 - accuracy: 0.6108 - val_loss: 0.6328 - val_accuracy: 0.6302\n","Epoch 7/1024\n","23/23 [==============================] - 498s 22s/step - loss: 0.6425 - accuracy: 0.6249 - val_loss: 0.6312 - val_accuracy: 0.6337\n","Epoch 8/1024\n","23/23 [==============================] - 500s 22s/step - loss: 0.6407 - accuracy: 0.6254 - val_loss: 0.6367 - val_accuracy: 0.6321\n","Epoch 9/1024\n","23/23 [==============================] - 498s 22s/step - loss: 0.6418 - accuracy: 0.6246 - val_loss: 0.6335 - val_accuracy: 0.6364\n","Epoch 10/1024\n","23/23 [==============================] - 498s 22s/step - loss: 0.6397 - accuracy: 0.6279 - val_loss: 0.6277 - val_accuracy: 0.6318\n","Epoch 11/1024\n","23/23 [==============================] - 503s 22s/step - loss: 0.6364 - accuracy: 0.6285 - val_loss: 0.6252 - val_accuracy: 0.6379\n","Epoch 12/1024\n","23/23 [==============================] - 506s 22s/step - loss: 0.6353 - accuracy: 0.6264 - val_loss: 0.6225 - val_accuracy: 0.6364\n","Epoch 13/1024\n","23/23 [==============================] - 502s 22s/step - loss: 0.6356 - accuracy: 0.6269 - val_loss: 0.6199 - val_accuracy: 0.6422\n","Epoch 14/1024\n","23/23 [==============================] - 506s 22s/step - loss: 0.6335 - accuracy: 0.6318 - val_loss: 0.6187 - val_accuracy: 0.6476\n","Epoch 15/1024\n","23/23 [==============================] - 509s 22s/step - loss: 0.6320 - accuracy: 0.6257 - val_loss: 0.6213 - val_accuracy: 0.6383\n","Epoch 16/1024\n","23/23 [==============================] - 506s 22s/step - loss: 0.6293 - accuracy: 0.6309 - val_loss: 0.6148 - val_accuracy: 0.6356\n","Epoch 17/1024\n","23/23 [==============================] - 525s 23s/step - loss: 0.6252 - accuracy: 0.6397 - val_loss: 0.6108 - val_accuracy: 0.6499\n","Epoch 18/1024\n","23/23 [==============================] - 512s 22s/step - loss: 0.6241 - accuracy: 0.6422 - val_loss: 0.6090 - val_accuracy: 0.6662\n","Epoch 19/1024\n","23/23 [==============================] - 507s 22s/step - loss: 0.6230 - accuracy: 0.6465 - val_loss: 0.6058 - val_accuracy: 0.6723\n","Epoch 20/1024\n","23/23 [==============================] - 513s 22s/step - loss: 0.6231 - accuracy: 0.6429 - val_loss: 0.6040 - val_accuracy: 0.6739\n","Epoch 21/1024\n","23/23 [==============================] - 509s 22s/step - loss: 0.6214 - accuracy: 0.6426 - val_loss: 0.6129 - val_accuracy: 0.6484\n","Epoch 22/1024\n","23/23 [==============================] - 519s 23s/step - loss: 0.6200 - accuracy: 0.6399 - val_loss: 0.6059 - val_accuracy: 0.6461\n","Epoch 23/1024\n","23/23 [==============================] - 508s 22s/step - loss: 0.6190 - accuracy: 0.6410 - val_loss: 0.6039 - val_accuracy: 0.6553\n","Epoch 24/1024\n","23/23 [==============================] - 510s 22s/step - loss: 0.6182 - accuracy: 0.6428 - val_loss: 0.6032 - val_accuracy: 0.6507\n","Epoch 25/1024\n","23/23 [==============================] - 511s 22s/step - loss: 0.6174 - accuracy: 0.6439 - val_loss: 0.6046 - val_accuracy: 0.6592\n","Epoch 26/1024\n","23/23 [==============================] - 509s 22s/step - loss: 0.6214 - accuracy: 0.6369 - val_loss: 0.6075 - val_accuracy: 0.6526\n","Epoch 27/1024\n","23/23 [==============================] - 506s 22s/step - loss: 0.6178 - accuracy: 0.6415 - val_loss: 0.6012 - val_accuracy: 0.6480\n","Epoch 28/1024\n","23/23 [==============================] - 504s 22s/step - loss: 0.6167 - accuracy: 0.6423 - val_loss: 0.6010 - val_accuracy: 0.6515\n","Epoch 29/1024\n","23/23 [==============================] - 504s 22s/step - loss: 0.6162 - accuracy: 0.6434 - val_loss: 0.6016 - val_accuracy: 0.6584\n","Epoch 30/1024\n","23/23 [==============================] - 661s 29s/step - loss: 0.6180 - accuracy: 0.6418 - val_loss: 0.5987 - val_accuracy: 0.6453\n","Epoch 31/1024\n","23/23 [==============================] - 545s 24s/step - loss: 0.6171 - accuracy: 0.6403 - val_loss: 0.6024 - val_accuracy: 0.6464\n","Epoch 32/1024\n","23/23 [==============================] - 506s 22s/step - loss: 0.6161 - accuracy: 0.6426 - val_loss: 0.5987 - val_accuracy: 0.6491\n","Epoch 33/1024\n","23/23 [==============================] - 510s 22s/step - loss: 0.6148 - accuracy: 0.6462 - val_loss: 0.6045 - val_accuracy: 0.6484\n","Epoch 34/1024\n","23/23 [==============================] - 462s 20s/step - loss: 0.6165 - accuracy: 0.6470 - val_loss: 0.6009 - val_accuracy: 0.6658\n","Epoch 35/1024\n","23/23 [==============================] - 443s 19s/step - loss: 0.6161 - accuracy: 0.6490 - val_loss: 0.5979 - val_accuracy: 0.6677\n","Epoch 36/1024\n","23/23 [==============================] - 441s 19s/step - loss: 0.6144 - accuracy: 0.6520 - val_loss: 0.5976 - val_accuracy: 0.6673\n","Epoch 37/1024\n","23/23 [==============================] - 446s 19s/step - loss: 0.6131 - accuracy: 0.6567 - val_loss: 0.5968 - val_accuracy: 0.6712\n","Epoch 38/1024\n","23/23 [==============================] - 444s 19s/step - loss: 0.6123 - accuracy: 0.6564 - val_loss: 0.5968 - val_accuracy: 0.6735\n","Epoch 39/1024\n","23/23 [==============================] - 442s 19s/step - loss: 0.6135 - accuracy: 0.6576 - val_loss: 0.5964 - val_accuracy: 0.6723\n","Epoch 40/1024\n","23/23 [==============================] - 440s 19s/step - loss: 0.6142 - accuracy: 0.6547 - val_loss: 0.5952 - val_accuracy: 0.6758\n","Epoch 41/1024\n","23/23 [==============================] - 441s 19s/step - loss: 0.6119 - accuracy: 0.6588 - val_loss: 0.5921 - val_accuracy: 0.6754\n","Epoch 42/1024\n","23/23 [==============================] - 440s 19s/step - loss: 0.6109 - accuracy: 0.6619 - val_loss: 0.5964 - val_accuracy: 0.6708\n","Epoch 43/1024\n","23/23 [==============================] - 449s 20s/step - loss: 0.6128 - accuracy: 0.6591 - val_loss: 0.5941 - val_accuracy: 0.6797\n","Epoch 44/1024\n","23/23 [==============================] - 442s 19s/step - loss: 0.6102 - accuracy: 0.6648 - val_loss: 0.5940 - val_accuracy: 0.6804\n","Epoch 45/1024\n","23/23 [==============================] - 445s 19s/step - loss: 0.6092 - accuracy: 0.6637 - val_loss: 0.5908 - val_accuracy: 0.6801\n","Epoch 46/1024\n","23/23 [==============================] - 441s 19s/step - loss: 0.6088 - accuracy: 0.6657 - val_loss: 0.5904 - val_accuracy: 0.6801\n","Epoch 47/1024\n","23/23 [==============================] - 443s 19s/step - loss: 0.6098 - accuracy: 0.6646 - val_loss: 0.5925 - val_accuracy: 0.6820\n","Epoch 48/1024\n","23/23 [==============================] - 442s 19s/step - loss: 0.6083 - accuracy: 0.6651 - val_loss: 0.5899 - val_accuracy: 0.6839\n","Epoch 49/1024\n","23/23 [==============================] - 441s 19s/step - loss: 0.6085 - accuracy: 0.6668 - val_loss: 0.5984 - val_accuracy: 0.6696\n","Epoch 50/1024\n","23/23 [==============================] - 444s 19s/step - loss: 0.6106 - accuracy: 0.6624 - val_loss: 0.5931 - val_accuracy: 0.6750\n","Epoch 51/1024\n","23/23 [==============================] - 444s 19s/step - loss: 0.6080 - accuracy: 0.6664 - val_loss: 0.5908 - val_accuracy: 0.6808\n","Epoch 52/1024\n","23/23 [==============================] - 445s 19s/step - loss: 0.6056 - accuracy: 0.6688 - val_loss: 0.5931 - val_accuracy: 0.6816\n","Epoch 53/1024\n","23/23 [==============================] - 446s 19s/step - loss: 0.6079 - accuracy: 0.6672 - val_loss: 0.5903 - val_accuracy: 0.6774\n","Epoch 54/1024\n","23/23 [==============================] - 445s 19s/step - loss: 0.6061 - accuracy: 0.6694 - val_loss: 0.5893 - val_accuracy: 0.6739\n","Epoch 55/1024\n","23/23 [==============================] - 445s 19s/step - loss: 0.6040 - accuracy: 0.6707 - val_loss: 0.5883 - val_accuracy: 0.6793\n","Epoch 56/1024\n","23/23 [==============================] - 445s 19s/step - loss: 0.6029 - accuracy: 0.6724 - val_loss: 0.5876 - val_accuracy: 0.6816\n","Epoch 57/1024\n","23/23 [==============================] - 452s 20s/step - loss: 0.6019 - accuracy: 0.6739 - val_loss: 0.5867 - val_accuracy: 0.6801\n","Epoch 58/1024\n","23/23 [==============================] - 451s 20s/step - loss: 0.6017 - accuracy: 0.6750 - val_loss: 0.5854 - val_accuracy: 0.6812\n","Epoch 59/1024\n","23/23 [==============================] - 452s 20s/step - loss: 0.6039 - accuracy: 0.6696 - val_loss: 0.6121 - val_accuracy: 0.6542\n","Epoch 60/1024\n","23/23 [==============================] - 453s 20s/step - loss: 0.6150 - accuracy: 0.6536 - val_loss: 0.5937 - val_accuracy: 0.6689\n","Epoch 61/1024\n","23/23 [==============================] - 451s 20s/step - loss: 0.6061 - accuracy: 0.6716 - val_loss: 0.5871 - val_accuracy: 0.6835\n","Epoch 62/1024\n","23/23 [==============================] - 452s 20s/step - loss: 0.6046 - accuracy: 0.6740 - val_loss: 0.5870 - val_accuracy: 0.6820\n","Epoch 63/1024\n","23/23 [==============================] - 451s 20s/step - loss: 0.6018 - accuracy: 0.6739 - val_loss: 0.5868 - val_accuracy: 0.6835\n","Epoch 64/1024\n","23/23 [==============================] - 451s 20s/step - loss: 0.6007 - accuracy: 0.6754 - val_loss: 0.5869 - val_accuracy: 0.6820\n","Epoch 65/1024\n","23/23 [==============================] - 456s 20s/step - loss: 0.6008 - accuracy: 0.6788 - val_loss: 0.5875 - val_accuracy: 0.6804\n","Epoch 66/1024\n","23/23 [==============================] - 453s 20s/step - loss: 0.6016 - accuracy: 0.6761 - val_loss: 0.5853 - val_accuracy: 0.6855\n","Epoch 67/1024\n","23/23 [==============================] - 455s 20s/step - loss: 0.6003 - accuracy: 0.6782 - val_loss: 0.5862 - val_accuracy: 0.6828\n","Epoch 68/1024\n","23/23 [==============================] - 453s 20s/step - loss: 0.6003 - accuracy: 0.6777 - val_loss: 0.5855 - val_accuracy: 0.6855\n","Epoch 69/1024\n","23/23 [==============================] - 453s 20s/step - loss: 0.5995 - accuracy: 0.6765 - val_loss: 0.5829 - val_accuracy: 0.6870\n","Epoch 70/1024\n","23/23 [==============================] - 454s 20s/step - loss: 0.5996 - accuracy: 0.6791 - val_loss: 0.5866 - val_accuracy: 0.6812\n","Epoch 71/1024\n","23/23 [==============================] - 454s 20s/step - loss: 0.6025 - accuracy: 0.6772 - val_loss: 0.5857 - val_accuracy: 0.6866\n","Epoch 72/1024\n","23/23 [==============================] - 454s 20s/step - loss: 0.6012 - accuracy: 0.6761 - val_loss: 0.5825 - val_accuracy: 0.6882\n","Epoch 73/1024\n","23/23 [==============================] - 455s 20s/step - loss: 0.5993 - accuracy: 0.6785 - val_loss: 0.5891 - val_accuracy: 0.6808\n","Epoch 74/1024\n","23/23 [==============================] - 456s 20s/step - loss: 0.5993 - accuracy: 0.6787 - val_loss: 0.5844 - val_accuracy: 0.6843\n","Epoch 75/1024\n","23/23 [==============================] - 455s 20s/step - loss: 0.5991 - accuracy: 0.6770 - val_loss: 0.5840 - val_accuracy: 0.6878\n","Epoch 76/1024\n","23/23 [==============================] - 457s 20s/step - loss: 0.5992 - accuracy: 0.6797 - val_loss: 0.5850 - val_accuracy: 0.6851\n","Epoch 77/1024\n","23/23 [==============================] - 455s 20s/step - loss: 0.5994 - accuracy: 0.6791 - val_loss: 0.5825 - val_accuracy: 0.6870\n","Epoch 78/1024\n","23/23 [==============================] - 455s 20s/step - loss: 0.5977 - accuracy: 0.6770 - val_loss: 0.5833 - val_accuracy: 0.6878\n","Epoch 79/1024\n","23/23 [==============================] - 457s 20s/step - loss: 0.5986 - accuracy: 0.6785 - val_loss: 0.5832 - val_accuracy: 0.6889\n","Epoch 80/1024\n","23/23 [==============================] - 457s 20s/step - loss: 0.5981 - accuracy: 0.6783 - val_loss: 0.5800 - val_accuracy: 0.6909\n","Epoch 81/1024\n","12/23 [==============>...............] - ETA: 3:24 - loss: 0.5914 - accuracy: 0.6868"],"name":"stdout"}]}]}